{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crop Damage Assesment Using a Modified ReseNet34 Model\n",
        "\n",
        "This notebook will dive into building an image classifcation model to classify\n",
        "whether crops in an image are suffering drought, weeds, nutrient deficiency, or other factors such as wind or disease. This would help smallholder farm owners across all of Africa process their insurance claims faster in case of a drought or other circumstances that might affect their crops.\n",
        "\n",
        "The ~26k image dataset used for training was retrieved from zindi.africa."
      ],
      "metadata": {
        "id": "WNZZ7D8g4y_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czQzlWAEOHYm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZVEJOo6c9Dq"
      },
      "outputs": [],
      "source": [
        "!gdown 1GhKtnR2bUdXo6CTntL8ji4gtE9SUAWMo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px8XxN5xwz4P"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/CGIR.zip';"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf Processed_Images"
      ],
      "metadata": {
        "id": "fvkAHAq3SCda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Filters (Optional)\n",
        "\n",
        "\n",
        "In this case, sharpening is applied."
      ],
      "metadata": {
        "id": "EFh2ap64HTsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#sharpen the image\n",
        "def sharpen_image(image):\n",
        "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
        "    return image_sharp\n",
        "\n",
        "\n",
        "def process_images_in_folder(input_folder, output_folder):\n",
        "    # Make sure the input folder path exists\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"Input folder not found: {input_folder}\")\n",
        "        return\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        print(f\"Output folder created: {output_folder}\")\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    files = os.listdir(input_folder)\n",
        "\n",
        "    # Filter out non-image files (you can customize this based on your file extensions)\n",
        "    image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    # Process each image in the input folder\n",
        "    for image_file in image_files:\n",
        "        # Construct the full path to the input image\n",
        "        input_image_path = os.path.join(input_folder, image_file)\n",
        "\n",
        "        # Read the input image\n",
        "        image = cv2.imread(input_image_path)\n",
        "\n",
        "        # Check if the input image is valid\n",
        "        if image is None:\n",
        "            print(f\"Failed to read input image: {input_image_path}\")\n",
        "            continue\n",
        "\n",
        "        # Apply the gray_image function\n",
        "        processed_image = sharpen_image(image)\n",
        "\n",
        "        # Construct the full path to the output image\n",
        "        output_image_path = os.path.join(output_folder, image_file)\n",
        "\n",
        "        # Save the processed image\n",
        "        cv2.imwrite(output_image_path, processed_image * 255)\n",
        "\n",
        "        print(f\"Processed: {input_image_path} -> {output_image_path}\")\n",
        "\n",
        "# Specify the path to your input folder containing images\n",
        "input_folder_path = \"/content/CGIR/images\"\n",
        "\n",
        "# Specify the path to your output folder for processed images\n",
        "output_folder_path = \"/content/Processed_Images\"\n",
        "\n",
        "# Call the function to process images in the input folder and save to the output folder\n",
        "process_images_in_folder(input_folder_path, output_folder_path)"
      ],
      "metadata": {
        "id": "w66CfcKnaTzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Processedimgs.zip /content/Processed_Images"
      ],
      "metadata": {
        "id": "KJWa1sTAUtfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset + Upsampling\n",
        "Dataset was loaded from gooogle drive. Upsampling performed on underepresented classes to improve model genralizeability. In this case, the DR, ND and other classes are being duplicated several times to upsample the data. This puts each class at about 9000 images."
      ],
      "metadata": {
        "id": "9blZwlNRLo6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/Processedimgs.zip\")"
      ],
      "metadata": {
        "id": "TGPDeBYKU_KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFZ40VvYJeJh"
      },
      "outputs": [],
      "source": [
        "# Step 1: Read the CSV file\n",
        "data = pd.read_csv('/content/CGIR/Train.csv')\n",
        "\n",
        "wd_rows = data[data['damage'] == 'WD']\n",
        "random_wd_rows = wd_rows.sample(n=9000)\n",
        "G_rows = data[data['damage'] == 'G']\n",
        "random_G_rows = G_rows.sample(n=9000)\n",
        "\n",
        "DR_rows = data[data['damage'] == 'DR']\n",
        "for i in range(0, 1):\n",
        "  DR_rows = DR_rows.append(DR_rows, ignore_index=True)\n",
        "\n",
        "ND_rows = data[data['damage'] == 'ND']\n",
        "for i in range(0, 5):\n",
        "  ND_rows = ND_rows.append(ND_rows, ignore_index=True)\n",
        "\n",
        "other_rows = data[data['damage'] == 'other']\n",
        "for i in range(0, 30):\n",
        "  random_other_rows = other_rows.sample(n=270)\n",
        "  other_rows = other_rows.append(random_other_rows, ignore_index=True)\n",
        "\n",
        "data = random_wd_rows.append(random_G_rows, ignore_index=True)\n",
        "data = data.append(DR_rows, ignore_index=True)\n",
        "data = data.append(ND_rows, ignore_index=True)\n",
        "data = data.append(other_rows, ignore_index=True)\n",
        "\n",
        "# Shuffle the resulting dataframe for randomness\n",
        "data= data.sample(frac=1).reset_index(drop=True)\n",
        "value_counts = data['damage'].value_counts()\n",
        "\n",
        "# Print the count of a specific value (replace 'your_value' with the value you're interested in)\n",
        "print(\"Count of 'your_value':\", value_counts['other'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified ResNet34 Model\n",
        "\n",
        "Initially a standard ResNet34 architecture was used, but was then slightly modified by removing or adding layers. In the cell below, an improvement of 4-6% in accuracy was achieved over a regular ResNet34.\n",
        "\n"
      ],
      "metadata": {
        "id": "CCZF_qqMl7fo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GND-JLpEq942"
      },
      "outputs": [],
      "source": [
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(64)\n",
        "        self.res_2_2 = ResnetBlock(64)\n",
        "        self.res_3_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(128)\n",
        "        self.res_4_1 = ResnetBlock(128)\n",
        "        self.res_4_2 = ResnetBlock(128)\n",
        "        self.res_5_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_5_2 = ResnetBlock(256)\n",
        "        self.res_6_1 = ResnetBlock(256)\n",
        "        self.res_6_2 = ResnetBlock(256)\n",
        "        self.res_7_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_7_2 = ResnetBlock(512)\n",
        "        self.res_8_1 = ResnetBlock(1024, down_sample=True)\n",
        "        self.res_8_2 = ResnetBlock(1024)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.ann1 = Dense(128, activation='relu')\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1,\n",
        "                          self.res_4_2, self.res_5_1, self.res_5_2, self.res_6_1, self.res_6_2, self.res_7_1, self.res_7_2,\n",
        "                          self.res_8_1, self.res_8_2]:\n",
        "        # for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.ann1(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Image Generators\n",
        "\n",
        "Images were normalized, resized to 224x224 and data augmentation techniques were applied to increase variety in the duplicated images. A 70 to 30 split was used for training and validation datasets respectively, with a batch size of 64 being chosen through experimentation and many iterations."
      ],
      "metadata": {
        "id": "9Bnp88_YuLLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTQmMBpZGC9K"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.3,\n",
        "    rescale=1./255,  # scale pixel values to [0, 1]\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=data,\n",
        "    directory='/content/Processed_Images',\n",
        "    x_col='filename',\n",
        "    y_col='damage',\n",
        "    subset='training',\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode='sparse',  # since we have regression output\n",
        "    target_size=(224,224)  # default input size for ResNet50\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=data,\n",
        "    directory='/content/Processed_Images',\n",
        "    x_col='filename',\n",
        "    y_col='damage',\n",
        "    subset='validation',\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode='sparse',\n",
        "    target_size=(224,224)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRkJ9NnMrg6N"
      },
      "outputs": [],
      "source": [
        "model = ResNet18(5)\n",
        "model.build(input_shape = (None,224,224,3))\n",
        "\n",
        "model.compile(optimizer= Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tlJHFyAIy1Z"
      },
      "outputs": [],
      "source": [
        "# model = load_model(r'C:\\Users\\aiman\\Desktop\\DL_dataset\\model.h5')\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gg_dqAv0qbGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d41t1WVJa3qv"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/CGIR', save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Model on a Test Dataset\n"
      ],
      "metadata": {
        "id": "xvh6PxTJvFt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTnoOzc0a3qv"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('/content/CGIR/Test.csv')\n",
        "\n",
        "datagen_test = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./255  # scale pixel values to [0, 1]\n",
        ")\n",
        "\n",
        "test_generator = datagen_test.flow_from_dataframe(\n",
        "    dataframe=test_data,\n",
        "    directory=r'/content/CGIR/images',\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    seed=42,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    target_size=(224,224)  # default input size for ResNet50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbhyAKLAa3qv"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/CGIR')\n",
        "predictions = model.predict(test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating CSV File Containing Classifcations"
      ],
      "metadata": {
        "id": "o6lZ1fKmvNBq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHmPxtBCAjfh"
      },
      "outputs": [],
      "source": [
        "class_indices = train_generator.class_indices\n",
        "print(predictions)\n",
        "print(class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sMvw8D3BcUa"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns=class_indices.keys())\n",
        "predictionsDF = pd.DataFrame(predictions, columns=df.columns)\n",
        "df1 = pd.concat([df, predictionsDF])\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSu1qtPSa3qw"
      },
      "outputs": [],
      "source": [
        "# Extract 'ID' column from test_df\n",
        "ID_df = test_data[['ID']]\n",
        "result_df = pd.concat([ID_df, predictionsDF], axis =1)\n",
        "result_df.to_csv('predictions.csv', index=False)\n",
        "result_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moNPKack8okA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}